{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "77b29090",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mlflow in c:\\users\\bhand\\anaconda3\\envs\\prediction\\lib\\site-packages (3.1.0)\n",
      "Requirement already satisfied: mlflow-skinny==3.1.0 in c:\\users\\bhand\\anaconda3\\envs\\prediction\\lib\\site-packages (from mlflow) (3.1.0)\n",
      "Requirement already satisfied: Flask<4 in c:\\users\\bhand\\anaconda3\\envs\\prediction\\lib\\site-packages (from mlflow) (3.1.1)\n",
      "Requirement already satisfied: alembic!=1.10.0,<2 in c:\\users\\bhand\\anaconda3\\envs\\prediction\\lib\\site-packages (from mlflow) (1.16.1)\n",
      "Requirement already satisfied: docker<8,>=4.0.0 in c:\\users\\bhand\\anaconda3\\envs\\prediction\\lib\\site-packages (from mlflow) (7.1.0)\n",
      "Requirement already satisfied: graphene<4 in c:\\users\\bhand\\anaconda3\\envs\\prediction\\lib\\site-packages (from mlflow) (3.4.3)\n",
      "Requirement already satisfied: matplotlib<4 in c:\\users\\bhand\\anaconda3\\envs\\prediction\\lib\\site-packages (from mlflow) (3.10.3)\n",
      "Requirement already satisfied: numpy<3 in c:\\users\\bhand\\appdata\\roaming\\python\\python313\\site-packages (from mlflow) (2.1.2)\n",
      "Requirement already satisfied: pandas<3 in c:\\users\\bhand\\anaconda3\\envs\\prediction\\lib\\site-packages (from mlflow) (2.2.3)\n",
      "Requirement already satisfied: pyarrow<21,>=4.0.0 in c:\\users\\bhand\\anaconda3\\envs\\prediction\\lib\\site-packages (from mlflow) (19.0.1)\n",
      "Requirement already satisfied: scikit-learn<2 in c:\\users\\bhand\\anaconda3\\envs\\prediction\\lib\\site-packages (from mlflow) (1.6.1)\n",
      "Requirement already satisfied: scipy<2 in c:\\users\\bhand\\anaconda3\\envs\\prediction\\lib\\site-packages (from mlflow) (1.15.1)\n",
      "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in c:\\users\\bhand\\anaconda3\\envs\\prediction\\lib\\site-packages (from mlflow) (2.0.41)\n",
      "Requirement already satisfied: waitress<4 in c:\\users\\bhand\\anaconda3\\envs\\prediction\\lib\\site-packages (from mlflow) (3.0.2)\n",
      "Requirement already satisfied: cachetools<7,>=5.0.0 in c:\\users\\bhand\\anaconda3\\envs\\prediction\\lib\\site-packages (from mlflow-skinny==3.1.0->mlflow) (5.5.2)\n",
      "Requirement already satisfied: click<9,>=7.0 in c:\\users\\bhand\\anaconda3\\envs\\prediction\\lib\\site-packages (from mlflow-skinny==3.1.0->mlflow) (8.1.8)\n",
      "Requirement already satisfied: cloudpickle<4 in c:\\users\\bhand\\anaconda3\\envs\\prediction\\lib\\site-packages (from mlflow-skinny==3.1.0->mlflow) (3.1.1)\n",
      "Requirement already satisfied: databricks-sdk<1,>=0.20.0 in c:\\users\\bhand\\anaconda3\\envs\\prediction\\lib\\site-packages (from mlflow-skinny==3.1.0->mlflow) (0.56.0)\n",
      "Requirement already satisfied: fastapi<1 in c:\\users\\bhand\\anaconda3\\envs\\prediction\\lib\\site-packages (from mlflow-skinny==3.1.0->mlflow) (0.115.12)\n",
      "Requirement already satisfied: gitpython<4,>=3.1.9 in c:\\users\\bhand\\anaconda3\\envs\\prediction\\lib\\site-packages (from mlflow-skinny==3.1.0->mlflow) (3.1.44)\n",
      "Requirement already satisfied: importlib_metadata!=4.7.0,<9,>=3.7.0 in c:\\users\\bhand\\anaconda3\\envs\\prediction\\lib\\site-packages (from mlflow-skinny==3.1.0->mlflow) (8.6.1)\n",
      "Requirement already satisfied: opentelemetry-api<3,>=1.9.0 in c:\\users\\bhand\\anaconda3\\envs\\prediction\\lib\\site-packages (from mlflow-skinny==3.1.0->mlflow) (1.34.1)\n",
      "Requirement already satisfied: opentelemetry-sdk<3,>=1.9.0 in c:\\users\\bhand\\anaconda3\\envs\\prediction\\lib\\site-packages (from mlflow-skinny==3.1.0->mlflow) (1.34.1)\n",
      "Requirement already satisfied: packaging<26 in c:\\users\\bhand\\anaconda3\\envs\\prediction\\lib\\site-packages (from mlflow-skinny==3.1.0->mlflow) (24.2)\n",
      "Requirement already satisfied: protobuf<7,>=3.12.0 in c:\\users\\bhand\\anaconda3\\envs\\prediction\\lib\\site-packages (from mlflow-skinny==3.1.0->mlflow) (5.29.3)\n",
      "Requirement already satisfied: pydantic<3,>=1.10.8 in c:\\users\\bhand\\anaconda3\\envs\\prediction\\lib\\site-packages (from mlflow-skinny==3.1.0->mlflow) (2.11.5)\n",
      "Requirement already satisfied: pyyaml<7,>=5.1 in c:\\users\\bhand\\anaconda3\\envs\\prediction\\lib\\site-packages (from mlflow-skinny==3.1.0->mlflow) (6.0.2)\n",
      "Requirement already satisfied: requests<3,>=2.17.3 in c:\\users\\bhand\\anaconda3\\envs\\prediction\\lib\\site-packages (from mlflow-skinny==3.1.0->mlflow) (2.32.3)\n",
      "Requirement already satisfied: sqlparse<1,>=0.4.0 in c:\\users\\bhand\\anaconda3\\envs\\prediction\\lib\\site-packages (from mlflow-skinny==3.1.0->mlflow) (0.5.3)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.0.0 in c:\\users\\bhand\\appdata\\roaming\\python\\python313\\site-packages (from mlflow-skinny==3.1.0->mlflow) (4.12.2)\n",
      "Requirement already satisfied: uvicorn<1 in c:\\users\\bhand\\anaconda3\\envs\\prediction\\lib\\site-packages (from mlflow-skinny==3.1.0->mlflow) (0.34.3)\n",
      "Requirement already satisfied: Mako in c:\\users\\bhand\\anaconda3\\envs\\prediction\\lib\\site-packages (from alembic!=1.10.0,<2->mlflow) (1.3.10)\n",
      "Requirement already satisfied: colorama in c:\\users\\bhand\\anaconda3\\envs\\prediction\\lib\\site-packages (from click<9,>=7.0->mlflow-skinny==3.1.0->mlflow) (0.4.6)\n",
      "Requirement already satisfied: google-auth~=2.0 in c:\\users\\bhand\\anaconda3\\envs\\prediction\\lib\\site-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny==3.1.0->mlflow) (2.40.3)\n",
      "Requirement already satisfied: pywin32>=304 in c:\\users\\bhand\\anaconda3\\envs\\prediction\\lib\\site-packages (from docker<8,>=4.0.0->mlflow) (307)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in c:\\users\\bhand\\anaconda3\\envs\\prediction\\lib\\site-packages (from docker<8,>=4.0.0->mlflow) (2.3.0)\n",
      "Requirement already satisfied: starlette<0.47.0,>=0.40.0 in c:\\users\\bhand\\anaconda3\\envs\\prediction\\lib\\site-packages (from fastapi<1->mlflow-skinny==3.1.0->mlflow) (0.46.2)\n",
      "Requirement already satisfied: blinker>=1.9.0 in c:\\users\\bhand\\anaconda3\\envs\\prediction\\lib\\site-packages (from Flask<4->mlflow) (1.9.0)\n",
      "Requirement already satisfied: itsdangerous>=2.2.0 in c:\\users\\bhand\\anaconda3\\envs\\prediction\\lib\\site-packages (from Flask<4->mlflow) (2.2.0)\n",
      "Requirement already satisfied: jinja2>=3.1.2 in c:\\users\\bhand\\appdata\\roaming\\python\\python313\\site-packages (from Flask<4->mlflow) (3.1.4)\n",
      "Requirement already satisfied: markupsafe>=2.1.1 in c:\\users\\bhand\\appdata\\roaming\\python\\python313\\site-packages (from Flask<4->mlflow) (2.1.5)\n",
      "Requirement already satisfied: werkzeug>=3.1.0 in c:\\users\\bhand\\anaconda3\\envs\\prediction\\lib\\site-packages (from Flask<4->mlflow) (3.1.3)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\bhand\\anaconda3\\envs\\prediction\\lib\\site-packages (from gitpython<4,>=3.1.9->mlflow-skinny==3.1.0->mlflow) (4.0.12)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\users\\bhand\\anaconda3\\envs\\prediction\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==3.1.0->mlflow) (5.0.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\bhand\\anaconda3\\envs\\prediction\\lib\\site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.1.0->mlflow) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\bhand\\anaconda3\\envs\\prediction\\lib\\site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.1.0->mlflow) (4.9.1)\n",
      "Requirement already satisfied: graphql-core<3.3,>=3.1 in c:\\users\\bhand\\anaconda3\\envs\\prediction\\lib\\site-packages (from graphene<4->mlflow) (3.2.6)\n",
      "Requirement already satisfied: graphql-relay<3.3,>=3.1 in c:\\users\\bhand\\anaconda3\\envs\\prediction\\lib\\site-packages (from graphene<4->mlflow) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil<3,>=2.7.0 in c:\\users\\bhand\\anaconda3\\envs\\prediction\\lib\\site-packages (from graphene<4->mlflow) (2.9.0.post0)\n",
      "Requirement already satisfied: zipp>=3.20 in c:\\users\\bhand\\anaconda3\\envs\\prediction\\lib\\site-packages (from importlib_metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==3.1.0->mlflow) (3.21.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\bhand\\anaconda3\\envs\\prediction\\lib\\site-packages (from matplotlib<4->mlflow) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\bhand\\anaconda3\\envs\\prediction\\lib\\site-packages (from matplotlib<4->mlflow) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\bhand\\anaconda3\\envs\\prediction\\lib\\site-packages (from matplotlib<4->mlflow) (4.58.2)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\bhand\\anaconda3\\envs\\prediction\\lib\\site-packages (from matplotlib<4->mlflow) (1.4.8)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\bhand\\appdata\\roaming\\python\\python313\\site-packages (from matplotlib<4->mlflow) (11.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\bhand\\anaconda3\\envs\\prediction\\lib\\site-packages (from matplotlib<4->mlflow) (3.2.3)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.55b1 in c:\\users\\bhand\\anaconda3\\envs\\prediction\\lib\\site-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==3.1.0->mlflow) (0.55b1)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\bhand\\anaconda3\\envs\\prediction\\lib\\site-packages (from pandas<3->mlflow) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\bhand\\anaconda3\\envs\\prediction\\lib\\site-packages (from pandas<3->mlflow) (2023.3)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\bhand\\anaconda3\\envs\\prediction\\lib\\site-packages (from pydantic<3,>=1.10.8->mlflow-skinny==3.1.0->mlflow) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\bhand\\anaconda3\\envs\\prediction\\lib\\site-packages (from pydantic<3,>=1.10.8->mlflow-skinny==3.1.0->mlflow) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\bhand\\anaconda3\\envs\\prediction\\lib\\site-packages (from pydantic<3,>=1.10.8->mlflow-skinny==3.1.0->mlflow) (0.4.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\bhand\\anaconda3\\envs\\prediction\\lib\\site-packages (from python-dateutil<3,>=2.7.0->graphene<4->mlflow) (1.17.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\bhand\\anaconda3\\envs\\prediction\\lib\\site-packages (from requests<3,>=2.17.3->mlflow-skinny==3.1.0->mlflow) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\bhand\\anaconda3\\envs\\prediction\\lib\\site-packages (from requests<3,>=2.17.3->mlflow-skinny==3.1.0->mlflow) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\bhand\\anaconda3\\envs\\prediction\\lib\\site-packages (from requests<3,>=2.17.3->mlflow-skinny==3.1.0->mlflow) (2025.1.31)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in c:\\users\\bhand\\anaconda3\\envs\\prediction\\lib\\site-packages (from rsa<5,>=3.1.4->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.1.0->mlflow) (0.6.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\bhand\\anaconda3\\envs\\prediction\\lib\\site-packages (from scikit-learn<2->mlflow) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\bhand\\anaconda3\\envs\\prediction\\lib\\site-packages (from scikit-learn<2->mlflow) (3.5.0)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\users\\bhand\\anaconda3\\envs\\prediction\\lib\\site-packages (from sqlalchemy<3,>=1.4.0->mlflow) (3.2.3)\n",
      "Requirement already satisfied: anyio<5,>=3.6.2 in c:\\users\\bhand\\anaconda3\\envs\\prediction\\lib\\site-packages (from starlette<0.47.0,>=0.40.0->fastapi<1->mlflow-skinny==3.1.0->mlflow) (4.9.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\bhand\\anaconda3\\envs\\prediction\\lib\\site-packages (from anyio<5,>=3.6.2->starlette<0.47.0,>=0.40.0->fastapi<1->mlflow-skinny==3.1.0->mlflow) (1.3.1)\n",
      "Requirement already satisfied: h11>=0.8 in c:\\users\\bhand\\anaconda3\\envs\\prediction\\lib\\site-packages (from uvicorn<1->mlflow-skinny==3.1.0->mlflow) (0.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: xgboost in c:\\users\\bhand\\anaconda3\\envs\\prediction\\lib\\site-packages (3.0.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\bhand\\appdata\\roaming\\python\\python313\\site-packages (from xgboost) (2.1.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\bhand\\anaconda3\\envs\\prediction\\lib\\site-packages (from xgboost) (1.15.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting imbalanced-learn\n",
      "  Downloading imbalanced_learn-0.13.0-py3-none-any.whl.metadata (8.8 kB)\n",
      "Requirement already satisfied: numpy<3,>=1.24.3 in c:\\users\\bhand\\appdata\\roaming\\python\\python313\\site-packages (from imbalanced-learn) (2.1.2)\n",
      "Requirement already satisfied: scipy<2,>=1.10.1 in c:\\users\\bhand\\anaconda3\\envs\\prediction\\lib\\site-packages (from imbalanced-learn) (1.15.1)\n",
      "Requirement already satisfied: scikit-learn<2,>=1.3.2 in c:\\users\\bhand\\anaconda3\\envs\\prediction\\lib\\site-packages (from imbalanced-learn) (1.6.1)\n",
      "Collecting sklearn-compat<1,>=0.1 (from imbalanced-learn)\n",
      "  Downloading sklearn_compat-0.1.3-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: joblib<2,>=1.1.1 in c:\\users\\bhand\\anaconda3\\envs\\prediction\\lib\\site-packages (from imbalanced-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl<4,>=2.0.0 in c:\\users\\bhand\\anaconda3\\envs\\prediction\\lib\\site-packages (from imbalanced-learn) (3.5.0)\n",
      "Downloading imbalanced_learn-0.13.0-py3-none-any.whl (238 kB)\n",
      "Downloading sklearn_compat-0.1.3-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: sklearn-compat, imbalanced-learn\n",
      "\n",
      "   -------------------- ------------------- 1/2 [imbalanced-learn]\n",
      "   -------------------- ------------------- 1/2 [imbalanced-learn]\n",
      "   ---------------------------------------- 2/2 [imbalanced-learn]\n",
      "\n",
      "Successfully installed imbalanced-learn-0.13.0 sklearn-compat-0.1.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install mlflow\n",
    "%pip install xgboost\n",
    "%pip install imbalanced-learn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503a80ac",
   "metadata": {},
   "source": [
    "## Import The Datasets using Pandas and read_csv function\n",
    "## Also Drop useless/ non feature columns like names\n",
    "## Check for missing values with .isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3160bb53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diabetes Dataset:\n",
      "    Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
      "0            6      148             72             35        0  33.6   \n",
      "1            1       85             66             29        0  26.6   \n",
      "2            8      183             64              0        0  23.3   \n",
      "3            1       89             66             23       94  28.1   \n",
      "4            0      137             40             35      168  43.1   \n",
      "\n",
      "   DiabetesPedigreeFunction  Age  Outcome  \n",
      "0                     0.627   50        1  \n",
      "1                     0.351   31        0  \n",
      "2                     0.672   32        1  \n",
      "3                     0.167   21        0  \n",
      "4                     2.288   33        1   \n",
      "\n",
      "Heart Disease Dataset:\n",
      "    age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
      "0   63    1   0       145   233    1        2      150      0      2.3      2   \n",
      "1   67    1   3       160   286    0        2      108      1      1.5      1   \n",
      "2   67    1   3       120   229    0        2      129      1      2.6      1   \n",
      "3   37    1   2       130   250    0        0      187      0      3.5      2   \n",
      "4   41    0   1       130   204    0        2      172      0      1.4      0   \n",
      "\n",
      "   ca  thal  target  \n",
      "0   0     2       0  \n",
      "1   3     1       1  \n",
      "2   2     3       1  \n",
      "3   0     1       0  \n",
      "4   0     1       0   \n",
      "\n",
      "parkinsons Disease Dataset:\n",
      "    MDVP:Fo(Hz)  MDVP:Fhi(Hz)  MDVP:Flo(Hz)  MDVP:Jitter(%)  MDVP:Jitter(Abs)  \\\n",
      "0      119.992       157.302        74.997         0.00784           0.00007   \n",
      "1      122.400       148.650       113.819         0.00968           0.00008   \n",
      "2      116.682       131.111       111.555         0.01050           0.00009   \n",
      "3      116.676       137.871       111.366         0.00997           0.00009   \n",
      "4      116.014       141.781       110.655         0.01284           0.00011   \n",
      "\n",
      "   MDVP:RAP  MDVP:PPQ  Jitter:DDP  MDVP:Shimmer  MDVP:Shimmer(dB)  ...  \\\n",
      "0   0.00370   0.00554     0.01109       0.04374             0.426  ...   \n",
      "1   0.00465   0.00696     0.01394       0.06134             0.626  ...   \n",
      "2   0.00544   0.00781     0.01633       0.05233             0.482  ...   \n",
      "3   0.00502   0.00698     0.01505       0.05492             0.517  ...   \n",
      "4   0.00655   0.00908     0.01966       0.06425             0.584  ...   \n",
      "\n",
      "   Shimmer:DDA      NHR     HNR  status      RPDE       DFA   spread1  \\\n",
      "0      0.06545  0.02211  21.033       1  0.414783  0.815285 -4.813031   \n",
      "1      0.09403  0.01929  19.085       1  0.458359  0.819521 -4.075192   \n",
      "2      0.08270  0.01309  20.651       1  0.429895  0.825288 -4.443179   \n",
      "3      0.08771  0.01353  20.644       1  0.434969  0.819235 -4.117501   \n",
      "4      0.10470  0.01767  19.649       1  0.417356  0.823484 -3.747787   \n",
      "\n",
      "    spread2        D2       PPE  \n",
      "0  0.266482  2.301442  0.284654  \n",
      "1  0.335590  2.486855  0.368674  \n",
      "2  0.311173  2.342259  0.332634  \n",
      "3  0.334147  2.405554  0.368975  \n",
      "4  0.234513  2.332180  0.410335  \n",
      "\n",
      "[5 rows x 23 columns] \n",
      "\n",
      "Missing Values:\n",
      "\n",
      "Diabetes:\n",
      " Pregnancies                 0\n",
      "Glucose                     0\n",
      "BloodPressure               0\n",
      "SkinThickness               0\n",
      "Insulin                     0\n",
      "BMI                         0\n",
      "DiabetesPedigreeFunction    0\n",
      "Age                         0\n",
      "Outcome                     0\n",
      "dtype: int64 \n",
      "\n",
      "Heart:\n",
      " age         0\n",
      "sex         0\n",
      "cp          0\n",
      "trestbps    0\n",
      "chol        0\n",
      "fbs         0\n",
      "restecg     0\n",
      "thalach     0\n",
      "exang       0\n",
      "oldpeak     0\n",
      "slope       0\n",
      "ca          0\n",
      "thal        0\n",
      "target      0\n",
      "dtype: int64 \n",
      "\n",
      "parkinsons:\n",
      " MDVP:Fo(Hz)         0\n",
      "MDVP:Fhi(Hz)        0\n",
      "MDVP:Flo(Hz)        0\n",
      "MDVP:Jitter(%)      0\n",
      "MDVP:Jitter(Abs)    0\n",
      "MDVP:RAP            0\n",
      "MDVP:PPQ            0\n",
      "Jitter:DDP          0\n",
      "MDVP:Shimmer        0\n",
      "MDVP:Shimmer(dB)    0\n",
      "Shimmer:APQ3        0\n",
      "Shimmer:APQ5        0\n",
      "MDVP:APQ            0\n",
      "Shimmer:DDA         0\n",
      "NHR                 0\n",
      "HNR                 0\n",
      "status              0\n",
      "RPDE                0\n",
      "DFA                 0\n",
      "spread1             0\n",
      "spread2             0\n",
      "D2                  0\n",
      "PPE                 0\n",
      "dtype: int64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd  \n",
    "import os\n",
    "\n",
    "# Load Datasets\n",
    "data_path_d = os.path.join('..', 'Datasets', 'diabetes.csv')\n",
    "data_path_h = os.path.join('..', 'Datasets', 'heart_disease.csv')\n",
    "data_path_p = os.path.join('..', 'Datasets', 'parkinsons.csv')\n",
    "\n",
    "# Load Datasets\n",
    "diabetes = pd.read_csv(data_path_d)\n",
    "heart = pd.read_csv(data_path_h)\n",
    "parkinsons = pd.read_csv(data_path_p)\n",
    "\n",
    "# Drop name column as its useless\n",
    "parkinsons = parkinsons.drop(columns=['name'], axis=1)\n",
    "\n",
    "# Display first few rows\n",
    "print(\"Diabetes Dataset:\\n\", diabetes.head(), \"\\n\")\n",
    "print(\"Heart Disease Dataset:\\n\", heart.head(), \"\\n\")\n",
    "print(\"parkinsons Disease Dataset:\\n\", parkinsons.head(), \"\\n\")\n",
    "\n",
    "# Check for missing values\n",
    "print(\"Missing Values:\\n\")\n",
    "print(\"Diabetes:\\n\", diabetes.isnull().sum(), \"\\n\")\n",
    "print(\"Heart:\\n\", heart.isnull().sum(), \"\\n\")\n",
    "print(\"parkinsons:\\n\", parkinsons.isnull().sum(), \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37366b89",
   "metadata": {},
   "source": [
    "## Create Scalers to mitigate Bias towards Large values and or way too small values\n",
    "## Use joblib to dump them in respective folders\n",
    "## Output before and after scaling\n",
    "## Create train/test split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7029b8bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEFORE SCALING:\n",
      "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
      "0            6      148             72             35        0  33.6   \n",
      "1            1       85             66             29        0  26.6   \n",
      "2            8      183             64              0        0  23.3   \n",
      "3            1       89             66             23       94  28.1   \n",
      "4            0      137             40             35      168  43.1   \n",
      "\n",
      "   DiabetesPedigreeFunction  Age  \n",
      "0                     0.627   50  \n",
      "1                     0.351   31  \n",
      "2                     0.672   32  \n",
      "3                     0.167   21  \n",
      "4                     2.288   33  \n",
      "\n",
      "AFTER SCALING:\n",
      "   Pregnancies   Glucose  BloodPressure  SkinThickness   Insulin       BMI  \\\n",
      "0     0.639947  0.848324       0.149641       0.907270 -0.692891  0.204013   \n",
      "1    -0.844885 -1.123396      -0.160546       0.530902 -0.692891 -0.684422   \n",
      "2     1.233880  1.943724      -0.263941      -1.288212 -0.692891 -1.103255   \n",
      "3    -0.844885 -0.998208      -0.160546       0.154533  0.123302 -0.494043   \n",
      "4    -1.141852  0.504055      -1.504687       0.907270  0.765836  1.409746   \n",
      "\n",
      "   DiabetesPedigreeFunction       Age  \n",
      "0                  0.468492  1.425995  \n",
      "1                 -0.365061 -0.190672  \n",
      "2                  0.604397 -0.105584  \n",
      "3                 -0.920763 -1.041549  \n",
      "4                  5.484909 -0.020496  \n",
      "BEFORE SCALING:\n",
      "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
      "0   63    1   0       145   233    1        2      150      0      2.3      2   \n",
      "1   67    1   3       160   286    0        2      108      1      1.5      1   \n",
      "2   67    1   3       120   229    0        2      129      1      2.6      1   \n",
      "3   37    1   2       130   250    0        0      187      0      3.5      2   \n",
      "4   41    0   1       130   204    0        2      172      0      1.4      0   \n",
      "\n",
      "   ca  thal  \n",
      "0   0     2  \n",
      "1   3     1  \n",
      "2   2     3  \n",
      "3   0     1  \n",
      "4   0     1  \n",
      "\n",
      "AFTER SCALING:\n",
      "        age       sex        cp  trestbps      chol       fbs   restecg  \\\n",
      "0  0.948726  0.686202 -2.251775  0.757525 -0.264900  2.394438  1.016684   \n",
      "1  1.392002  0.686202  0.877985  1.611220  0.760415 -0.417635  1.016684   \n",
      "2  1.392002  0.686202  0.877985 -0.665300 -0.342283 -0.417635  1.016684   \n",
      "3 -1.932564  0.686202 -0.165268 -0.096170  0.063974 -0.417635 -0.996749   \n",
      "4 -1.489288 -1.457296 -1.208521 -0.096170 -0.825922 -0.417635  1.016684   \n",
      "\n",
      "    thalach     exang   oldpeak     slope        ca      thal  \n",
      "0  0.017197 -0.696631  1.087338  2.274579 -0.711131  0.176225  \n",
      "1 -1.821905  1.435481  0.397182  0.649113  2.504881 -0.870759  \n",
      "2 -0.902354  1.435481  1.346147  0.649113  1.432877  1.223208  \n",
      "3  1.637359 -0.696631  2.122573  2.274579 -0.711131 -0.870759  \n",
      "4  0.980537 -0.696631  0.310912 -0.976352 -0.711131 -0.870759  \n",
      "BEFORE SCALING:\n",
      "   MDVP:Fo(Hz)  MDVP:Fhi(Hz)  MDVP:Flo(Hz)  MDVP:Jitter(%)  MDVP:Jitter(Abs)  \\\n",
      "0      119.992       157.302        74.997         0.00784           0.00007   \n",
      "1      122.400       148.650       113.819         0.00968           0.00008   \n",
      "2      116.682       131.111       111.555         0.01050           0.00009   \n",
      "3      116.676       137.871       111.366         0.00997           0.00009   \n",
      "4      116.014       141.781       110.655         0.01284           0.00011   \n",
      "\n",
      "   MDVP:RAP  MDVP:PPQ  Jitter:DDP  MDVP:Shimmer  MDVP:Shimmer(dB)  ...  \\\n",
      "0   0.00370   0.00554     0.01109       0.04374             0.426  ...   \n",
      "1   0.00465   0.00696     0.01394       0.06134             0.626  ...   \n",
      "2   0.00544   0.00781     0.01633       0.05233             0.482  ...   \n",
      "3   0.00502   0.00698     0.01505       0.05492             0.517  ...   \n",
      "4   0.00655   0.00908     0.01966       0.06425             0.584  ...   \n",
      "\n",
      "   MDVP:APQ  Shimmer:DDA      NHR     HNR      RPDE       DFA   spread1  \\\n",
      "0   0.02971      0.06545  0.02211  21.033  0.414783  0.815285 -4.813031   \n",
      "1   0.04368      0.09403  0.01929  19.085  0.458359  0.819521 -4.075192   \n",
      "2   0.03590      0.08270  0.01309  20.651  0.429895  0.825288 -4.443179   \n",
      "3   0.03772      0.08771  0.01353  20.644  0.434969  0.819235 -4.117501   \n",
      "4   0.04465      0.10470  0.01767  19.649  0.417356  0.823484 -3.747787   \n",
      "\n",
      "    spread2        D2       PPE  \n",
      "0  0.266482  2.301442  0.284654  \n",
      "1  0.335590  2.486855  0.368674  \n",
      "2  0.311173  2.342259  0.332634  \n",
      "3  0.334147  2.405554  0.368975  \n",
      "4  0.234513  2.332180  0.410335  \n",
      "\n",
      "[5 rows x 22 columns]\n",
      "\n",
      "AFTER SCALING:\n",
      "   MDVP:Fo(Hz)  MDVP:Fhi(Hz)  MDVP:Flo(Hz)  MDVP:Jitter(%)  MDVP:Jitter(Abs)  \\\n",
      "0    -0.829300     -0.436165     -0.952037        0.334914          0.749759   \n",
      "1    -0.770972     -0.530974     -0.057721        0.715418          1.037674   \n",
      "2    -0.909476     -0.723168     -0.109875        0.884991          1.325589   \n",
      "3    -0.909622     -0.649092     -0.114229        0.775389          1.325589   \n",
      "4    -0.925657     -0.606245     -0.130608        1.368893          1.901418   \n",
      "\n",
      "   MDVP:RAP  MDVP:PPQ  Jitter:DDP  MDVP:Shimmer  MDVP:Shimmer(dB)  ...  \\\n",
      "0  0.132963  0.760800    0.131755      0.745985          0.739536  ...   \n",
      "1  0.453892  1.276809    0.452684      1.681731          1.768464  ...   \n",
      "2  0.720770  1.585687    0.721813      1.202693          1.027636  ...   \n",
      "3  0.578885  1.284076    0.577677      1.340396          1.207698  ...   \n",
      "4  1.095750  2.047187    1.096793      1.836448          1.552389  ...   \n",
      "\n",
      "   MDVP:APQ  Shimmer:DDA       NHR       HNR      RPDE       DFA   spread1  \\\n",
      "0  0.332985     0.607532 -0.067893 -0.193225 -0.807838  1.760814  0.801323   \n",
      "1  1.159454     1.548254 -0.137843 -0.634508 -0.387524  1.837562  1.479853   \n",
      "2  0.699187     1.175323 -0.291633 -0.279760 -0.662075  1.942048  1.141445   \n",
      "3  0.806859     1.340229 -0.280719 -0.281346 -0.613134  1.832380  1.440945   \n",
      "4  1.216839     1.899461 -0.178026 -0.506745 -0.783021  1.909364  1.780940   \n",
      "\n",
      "    spread2        D2       PPE  \n",
      "0  0.480477 -0.210531  0.868886  \n",
      "1  1.311185  0.275077  1.803605  \n",
      "2  1.017682 -0.103629  1.402661  \n",
      "3  1.293840  0.062145  1.806954  \n",
      "4  0.096195 -0.130026  2.267082  \n",
      "\n",
      "[5 rows x 22 columns]\n",
      "Preprocessing Completed and saved Scalers to designated folder...\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def preprocess_data(disease_frame, target_feature, scaler_path):\n",
    "    # Seperate Features to train on and the output of the data\n",
    "    X = disease_frame.drop(columns=[target_feature])\n",
    "    Y = disease_frame[target_feature]\n",
    "\n",
    "    # Use Standard Scaler to scale the features and fix Extreme high and extreme low values and store it in the folder\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    # Values Before Scaling\n",
    "    print(\"BEFORE SCALING:\")\n",
    "    print(X.head())\n",
    "    \n",
    "    # Apply the Scaler to X\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    # Display the first few rows of the scaled data\n",
    "    print(\"\\nAFTER SCALING:\")\n",
    "    X_scaled_df = pd.DataFrame(X_scaled, columns=X.columns)\n",
    "    print(X_scaled_df.head())\n",
    "\n",
    "    # Save the scalers to the specified path\n",
    "    joblib.dump(scaler, scaler_path)\n",
    "\n",
    "    # Create a train test Split for verifying Model metrics, using random_state = 42 reference to Hitchhiker's Guide to the Galaxy for consistent splits\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X_scaled, Y, test_size = 0.2, random_state = 42)\n",
    "    \n",
    "    # Return the train and test data\n",
    "    return X_train, X_test , Y_train, Y_test\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Main Function Call to store Preprocessed Data in respective variables\n",
    "\n",
    "X_train_diabetes, X_test_diabetes, y_train_diabetes, y_test_diabetes = preprocess_data(diabetes, \"Outcome\", os.path.join('..','Trained_Models/Scalers/diabetes_scaler.pkl'))\n",
    "X_train_heart, X_test_heart, y_train_heart, y_test_heart = preprocess_data(heart, \"target\", os.path.join('..','Trained_Models/Scalers/heart_scaler.pkl'))\n",
    "X_train_parkinsons, X_test_parkinsons, y_train_parkinsons, y_test_parkinsons = preprocess_data(parkinsons, \"status\", os.path.join('..','Trained_Models/Scalers/parkinsons_scaler.pkl'))\n",
    "\n",
    "print(\"Preprocessing Completed and saved Scalers to designated folder...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b4bce2",
   "metadata": {},
   "source": [
    "## Initiate MLFLOW for Comparison and Tracking\n",
    "## Train Models with Multiple Algorthims RFC, LR, KNN, XGBClassifier\n",
    "## Saved the Models in their Respective folders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f81c446c",
   "metadata": {},
   "source": [
    "## Add MLFLOW LOGGING\n",
    "## Modify below command as needed\n",
    "## Run via mlflow ui --backend-store-uri \"file:///E:/Github Projects/MlOps MDP/MLOPS/Jupyter Notebooks/Mlflow\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17b23e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Mlflow libraries for Logging\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import mlflow.xgboost\n",
    "import pandas as pd\n",
    "from mlflow.data.pandas_dataset import PandasDataset\n",
    "from mlflow.data.sources import LocalArtifactDatasetSource\n",
    "\n",
    "\n",
    "# Import Machine Learning Algorithms \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Import Metrics from sklearn\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from mlflow.models.signature import infer_signature\n",
    "\n",
    "def train_model_with_mlflow(X_Train, Y_Train, X_Test, Y_Test, disease_name, dataset):\n",
    "    # Create experiment \n",
    "    mlflow.set_experiment(disease_name)\n",
    "    \n",
    "    # Create directories if they don't exist\n",
    "    os.makedirs(os.path.join('..', 'Trained_Models', disease_name), exist_ok=True)\n",
    "    \n",
    "    # Dictionary of models\n",
    "    models = {\n",
    "        \"LogisticRegression\": LogisticRegression(max_iter=1000),\n",
    "        \"RandomForest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "        \"KNN\": KNeighborsClassifier(n_neighbors=5),\n",
    "        \"XGBoost\": XGBClassifier(random_state=42)\n",
    "    }\n",
    "    \n",
    "    # Create input example for model signature\n",
    "    input_example = X_Train[:5]\n",
    "    \n",
    "    for model_name, model in models.items():\n",
    "        # Start a new run for each model\n",
    "        with mlflow.start_run(run_name=model_name):\n",
    "            # Train model\n",
    "            model.fit(X_Train, Y_Train)\n",
    "            \n",
    "            # Make predictions\n",
    "            y_pred = model.predict(X_Test)\n",
    "            \n",
    "            # Infer model signature\n",
    "            signature = infer_signature(X_Train, y_pred)\n",
    "            \n",
    "            # Calculate metrics\n",
    "            metrics = {\n",
    "                \"accuracy\": accuracy_score(Y_Test, y_pred),\n",
    "                \"precision\": precision_score(Y_Test, y_pred, zero_division=0),\n",
    "                \"recall\": recall_score(Y_Test, y_pred, zero_division=0),\n",
    "                \"f1_score\": f1_score(Y_Test, y_pred, zero_division=0)\n",
    "            }\n",
    "            \n",
    "            # Print results\n",
    "            print(f\"\\n{disease_name} - {model_name} Results:\")\n",
    "            for metric_name, value in metrics.items():\n",
    "                print(f\"{metric_name}: {value:.4f}\")\n",
    "            \n",
    "            # Log metrics to MLflow\n",
    "            mlflow.log_metrics(metrics)\n",
    "            \n",
    "            # Test dataset import\n",
    "            mlflow.log_input(dataset, context=\"training\")\n",
    "\n",
    "            # Log model parameters\n",
    "            mlflow.log_params(model.get_params())\n",
    "            \n",
    "            # Log the model with signature and input example\n",
    "            if isinstance(model, XGBClassifier):\n",
    "                mlflow.xgboost.log_model(\n",
    "                    model, \n",
    "                    name=model_name,\n",
    "                    signature=signature,\n",
    "                    input_example=input_example\n",
    "                )\n",
    "            else:\n",
    "                mlflow.sklearn.log_model(\n",
    "                    model, \n",
    "                    name=model_name,\n",
    "                    signature=signature,\n",
    "                    input_example=input_example\n",
    "                )\n",
    "            \n",
    "            # Save model locally\n",
    "            joblib.dump(model, os.path.join('..', 'Trained_Models', disease_name, f'{model_name}_model.pkl'))\n",
    "\n",
    "# Set MLflow tracking URI and create experiments\n",
    "mlflow_dir = os.path.abspath(\"Mlflow\")  # Converts to something like E:/Your/Path/Mlflow\n",
    "os.makedirs(mlflow_dir, exist_ok=True) \n",
    "mlflow.set_tracking_uri(f\"file:///{mlflow_dir.replace(os.sep, '/')}\")\n",
    "\n",
    "# pre-load datasets for ml-flow\n",
    "diabetes_mlflow: PandasDataset = mlflow.data.from_pandas(diabetes, source=LocalArtifactDatasetSource(data_path_d))\n",
    "heart_mlflow: PandasDataset = mlflow.data.from_pandas(diabetes, source= LocalArtifactDatasetSource(data_path_h))\n",
    "parkinsons_mlflow: PandasDataset = mlflow.data.from_pandas(diabetes, source= LocalArtifactDatasetSource(data_path_p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde78fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and log models\n",
    "train_model_with_mlflow(X_train_diabetes, y_train_diabetes,X_test_diabetes, y_test_diabetes,\"Diabetes_Experiment\", diabetes_mlflow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a479a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model_with_mlflow(X_train_heart,y_train_heart,X_test_heart,y_test_heart,\"Heart_Disease_Experiment\", heart_mlflow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe3f008",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model_with_mlflow(X_train_parkinsons, y_train_parkinsons,X_test_parkinsons, y_test_parkinsons,\"Parkinsons_Experiment\", parkinsons_mlflow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f204ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mlflow.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d067ff",
   "metadata": {},
   "source": [
    "## Diabetes has sub-par accuracy mertics try to tune it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69ebed8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from mlflow.models.signature import infer_signature\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import pandas as pd\n",
    "from mlflow.data.pandas_dataset import PandasDataset\n",
    "from mlflow.data.sources import LocalArtifactDatasetSource\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import os\n",
    "\n",
    "# Set Custom MLflow tracking URI and create experiments\n",
    "mlflow_dir = os.path.abspath(\"Mlflow\")  # Converts to something like E:/Your/Path/Mlflow\n",
    "os.makedirs(mlflow_dir, exist_ok=True) \n",
    "mlflow.set_tracking_uri(f\"file:///{mlflow_dir.replace(os.sep, '/')}\")\n",
    "\n",
    "# Set Dataset tracking\n",
    "diabetes_mlflow: PandasDataset = mlflow.data.from_pandas(diabetes, source=LocalArtifactDatasetSource(data_path_d))\n",
    "heart_mlflow: PandasDataset = mlflow.data.from_pandas(diabetes, source= LocalArtifactDatasetSource(data_path_h))\n",
    "parkinsons_mlflow: PandasDataset = mlflow.data.from_pandas(diabetes, source= LocalArtifactDatasetSource(data_path_p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e35265",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7597402597402597\n",
      "Precision: 0.6307692307692307\n",
      "Recall: 0.7592592592592593\n",
      "F1 Score: 0.6890756302521008\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from mlflow.models.signature import infer_signature\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import pandas as pd\n",
    "from mlflow.data.pandas_dataset import PandasDataset\n",
    "from mlflow.data.sources import LocalArtifactDatasetSource\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import os\n",
    "\n",
    "def Hyperparameter_tuning(X_train, X_test, y_train, y_test, dataset):\n",
    "    mlflow.set_experiment(\"HyperParameter-Tuning: Diabetes\")\n",
    "\n",
    "    with mlflow.start_run(run_name=\"LogisticTuning (Elk)\"):\n",
    "        param_grid = {\n",
    "            'penalty': ['elasticnet'],\n",
    "            'l1_ratio': [0.1, 0.5, 0.9],\n",
    "            'solver': ['saga'],\n",
    "            'class_weight' : ['balanced'],\n",
    "            'C': [0.01, 0.1, 1, 10]\n",
    "        }\n",
    "\n",
    "        grid = GridSearchCV(LogisticRegression(), param_grid, scoring='f1', cv=5)\n",
    "        grid.fit(X_train, y_train)\n",
    "\n",
    "        best_model = grid.best_estimator_\n",
    "        y_pred = best_model.predict(X_test)\n",
    "\n",
    "        # Infer model signature\n",
    "        signature = infer_signature(X_train, y_pred)\n",
    "\n",
    "        # Load Dataset info\n",
    "        mlflow.log_input(dataset, context=\"training\")\n",
    "\n",
    "        # Metrics\n",
    "        metrics = {\n",
    "            \"accuracy\": accuracy_score(y_test, y_pred),\n",
    "            \"precision\": precision_score(y_test, y_pred, zero_division=0),\n",
    "            \"recall\": recall_score(y_test, y_pred, zero_division=0),\n",
    "            \"f1_score\": f1_score(y_test, y_pred, zero_division=0)\n",
    "        }\n",
    "\n",
    "        mlflow.log_metrics(metrics)\n",
    "        mlflow.log_params(best_model.get_params())\n",
    "\n",
    "        # Optional: log a sample of test data as input example\n",
    "        input_example = X_test.iloc[:5] if hasattr(X_test, \"iloc\") else X_test[:5]\n",
    "\n",
    "        # Log the model\n",
    "        mlflow.sklearn.log_model(\n",
    "            best_model,\n",
    "            name=\"LogisticRegression\",\n",
    "            signature=signature,\n",
    "            input_example=input_example\n",
    "        )\n",
    "\n",
    "        # Print results\n",
    "        print(f\"Diabetes - Logistic Regression: Parameter-Tuning\")\n",
    "        for metric_name, value in metrics.items():\n",
    "            print(f\"{metric_name}: {value:.4f}\")\n",
    "\n",
    "# Function call\n",
    "Hyperparameter_tuning(X_train_diabetes, X_test_diabetes, y_train_diabetes, y_test_diabetes, diabetes_mlflow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "476d224e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7597402597402597\n",
      "Precision: 0.6307692307692307\n",
      "Recall: 0.7592592592592593\n",
      "F1 Score: 0.6890756302521008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Bhand\\anaconda3\\envs\\prediction\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from mlflow.models.signature import infer_signature\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import pandas as pd\n",
    "from mlflow.data.pandas_dataset import PandasDataset\n",
    "from mlflow.data.sources import LocalArtifactDatasetSource\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import os\n",
    "\n",
    "def SMOTE_Logging(X_train, X_test, y_test, dataset):\n",
    "    mlflow.set_experiment(\"HyperParameter-Tuning: Diabetes\")\n",
    "\n",
    "    with mlflow.start_run(run_name=\"LogisticTuning (SMOTE)\"):\n",
    "        # Load your diabetes dataset\n",
    "        df = pd.read_csv(data_path_d)  # Replace with your actual path or DataFrame\n",
    "        X = df.drop(columns=[\"Outcome\"])\n",
    "        y = df[\"Outcome\"]\n",
    "\n",
    "        # Train-test split\n",
    "        X_train_smote, X_test_smote, y_train_smote, y_test_smote = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "        # Apply SMOTE\n",
    "        smote = SMOTE(random_state=42)\n",
    "        X_train_resampled, y_train_resampled = smote.fit_resample(X_train_smote, y_train_smote)\n",
    "\n",
    "        # Train Logistic Regression\n",
    "        model = LogisticRegression(solver='liblinear')\n",
    "        model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "        # Predict\n",
    "        y_pred = model.predict(X_test_smote)\n",
    "\n",
    "        # Evaluate\n",
    "        print(\"Accuracy:\", accuracy_score(y_test_smote, y_pred))\n",
    "        print(\"Precision:\", precision_score(y_test_smote, y_pred))\n",
    "        print(\"Recall:\", recall_score(y_test_smote, y_pred))\n",
    "        print(\"F1 Score:\", f1_score(y_test_smote, y_pred))\n",
    "\n",
    "        # Infer model signature\n",
    "        signature = infer_signature(X_train, y_pred)\n",
    "\n",
    "        # Load Dataset info\n",
    "        mlflow.log_input(dataset, context=\"training\")\n",
    "\n",
    "        # Metrics\n",
    "        metrics = {\n",
    "            \"accuracy\": accuracy_score(y_test_smote, y_pred),\n",
    "            \"precision\": precision_score(y_test_smote, y_pred),\n",
    "            \"recall\": recall_score(y_test_smote, y_pred),\n",
    "            \"f1_score\": f1_score(y_test_smote, y_pred)\n",
    "        }\n",
    "\n",
    "        mlflow.log_metrics(metrics)\n",
    "\n",
    "        # Optional: log a sample of test data as input example\n",
    "        input_example = X_test.iloc[:5] if hasattr(X_test, \"iloc\") else X_test[:5]\n",
    "\n",
    "        # Log the model\n",
    "        mlflow.sklearn.log_model(\n",
    "            model,\n",
    "            name=\"LogisticRegression\",\n",
    "            signature=signature,\n",
    "            input_example=input_example\n",
    "        )\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "SMOTE_Logging(X_train_diabetes, X_test_diabetes, y_test_diabetes, diabetes_mlflow)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab4956e",
   "metadata": {},
   "source": [
    "## Logistic Regression not yielding good results even after multiple tuning stages\n",
    "## Moving on to XGBOOST as its a non-linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3cf2bbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Bhand\\anaconda3\\envs\\prediction\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [14:26:24] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\Bhand\\anaconda3\\envs\\prediction\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7727272727272727\n",
      "Precision: 0.6461538461538462\n",
      "Recall: 0.7777777777777778\n",
      "F1 Score: 0.7058823529411765\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from mlflow.models.signature import infer_signature\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import pandas as pd\n",
    "from mlflow.data.pandas_dataset import PandasDataset\n",
    "from mlflow.data.sources import LocalArtifactDatasetSource\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import os\n",
    "\n",
    "def SMOTE_Logging(X_train, X_test, y_test, dataset):\n",
    "    mlflow.set_experiment(\"HyperParameter-Tuning: Diabetes\")\n",
    "\n",
    "    with mlflow.start_run(run_name=\"XGBoost(SMOTE)\"):\n",
    "        # Load your diabetes dataset\n",
    "        df = pd.read_csv(data_path_d)  # Replace with your actual path or DataFrame\n",
    "        X = df.drop(columns=[\"Outcome\"])\n",
    "        y = df[\"Outcome\"]\n",
    "\n",
    "        # Train-test split\n",
    "        X_train_smote, X_test_smote, y_train_smote, y_test_smote = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "        # Apply SMOTE\n",
    "        smote = SMOTE(random_state=42)\n",
    "        X_train_resampled, y_train_resampled = smote.fit_resample(X_train_smote, y_train_smote)\n",
    "\n",
    "        # Train using XGB boost\n",
    "        model = XGBClassifier(n_estimators=100, max_depth=3, learning_rate=0.1, use_label_encoder=False, eval_metric='logloss')\n",
    "        \n",
    "        model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "        # Predict\n",
    "        y_pred = model.predict(X_test_smote)\n",
    "\n",
    "        # Evaluate\n",
    "        print(\"Accuracy:\", accuracy_score(y_test_smote, y_pred))\n",
    "        print(\"Precision:\", precision_score(y_test_smote, y_pred))\n",
    "        print(\"Recall:\", recall_score(y_test_smote, y_pred))\n",
    "        print(\"F1 Score:\", f1_score(y_test_smote, y_pred))\n",
    "\n",
    "        # Infer model signature\n",
    "        signature = infer_signature(X_train, y_pred)\n",
    "\n",
    "        # Load Dataset info\n",
    "        mlflow.log_input(dataset, context=\"training\")\n",
    "\n",
    "        # Metrics\n",
    "        metrics = {\n",
    "            \"accuracy\": accuracy_score(y_test_smote, y_pred),\n",
    "            \"precision\": precision_score(y_test_smote, y_pred),\n",
    "            \"recall\": recall_score(y_test_smote, y_pred),\n",
    "            \"f1_score\": f1_score(y_test_smote, y_pred)\n",
    "        }\n",
    "\n",
    "        mlflow.log_metrics(metrics)\n",
    "\n",
    "        # Optional: log a sample of test data as input example\n",
    "        input_example = X_test_smote.iloc[:5] if hasattr(X_test, \"iloc\") else X_test_smote[:5]\n",
    "\n",
    "        # Log the model\n",
    "        mlflow.sklearn.log_model(\n",
    "            model,\n",
    "            name=\"XGBoost (SMOTE)\",\n",
    "            signature=signature,\n",
    "            input_example=input_example\n",
    "        )\n",
    "\n",
    "SMOTE_Logging(X_train_diabetes, X_test_diabetes, y_test_diabetes, diabetes_mlflow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40904100",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 256 candidates, totalling 1280 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Bhand\\anaconda3\\envs\\prediction\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [14:46:38] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best parameters found:\n",
      "{'colsample_bytree': 0.8, 'gamma': 0, 'learning_rate': 0.1, 'max_depth': 5, 'min_child_weight': 1, 'n_estimators': 200, 'scale_pos_weight': 2, 'subsample': 0.8}\n",
      "\n",
      "Model Performance:\n",
      "Accuracy: 0.7727272727272727\n",
      "Precision: 0.6507936507936508\n",
      "Recall: 0.7592592592592593\n",
      "F1 Score: 0.7008547008547008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Bhand\\anaconda3\\envs\\prediction\\Lib\\site-packages\\xgboost\\sklearn.py:1028: UserWarning: [14:46:51] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\c_api\\c_api.cc:1427: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\n",
      "  self.get_booster().save_model(fname)\n"
     ]
    }
   ],
   "source": [
    "def SMOTE_Logging(X_train, X_test, y_test, dataset):\n",
    "    mlflow.set_experiment(\"HyperParameter-Tuning: Diabetes\")\n",
    "\n",
    "    with mlflow.start_run(run_name=\"XGBoost(SMOTE + Tuning + 5 Cross)\"):\n",
    "        # Load your diabetes dataset\n",
    "        df = pd.read_csv(data_path_d)\n",
    "        X = df.drop(columns=[\"Outcome\"])\n",
    "        y = df[\"Outcome\"]\n",
    "\n",
    "        # Train-test split\n",
    "        X_train_smote, X_test_smote, y_train_smote, y_test_smote = train_test_split(\n",
    "            X, y, test_size=0.2, stratify=y, random_state=42\n",
    "        )\n",
    "\n",
    "        # Find and apply scalers \n",
    "        scaler = joblib.load(os.path.join('..','Trained_Models/Scalers/diabetes_scaler.pkl'))\n",
    "        X_train_smote = scaler.transform(X_train_smote)\n",
    "        X_test_smote = scaler.transform(X_test_smote)\n",
    "\n",
    "        # Apply SMOTE\n",
    "        smote = SMOTE(random_state=42)\n",
    "        X_train_resampled, y_train_resampled = smote.fit_resample(X_train_smote, y_train_smote)\n",
    "\n",
    "        # Define parameter grid for XGBoost\n",
    "        param_grid = {\n",
    "            'n_estimators': [100, 200],\n",
    "            'max_depth': [3, 5],\n",
    "            'learning_rate': [0.01, 0.1],\n",
    "            'subsample': [0.8, 1.0],\n",
    "            'colsample_bytree': [0.8, 1.0],\n",
    "            'min_child_weight': [1, 3],\n",
    "            'gamma': [0, 0.1],\n",
    "            'scale_pos_weight': [1, 2]\n",
    "        }\n",
    "\n",
    "        # Initialize XGBoost with base parameters\n",
    "        xgb_model = XGBClassifier(\n",
    "            use_label_encoder=False,\n",
    "            eval_metric='logloss',\n",
    "            random_state=42\n",
    "        )\n",
    "\n",
    "        # Perform Grid Search\n",
    "        grid_search = GridSearchCV(\n",
    "            estimator=xgb_model,\n",
    "            param_grid=param_grid,\n",
    "            scoring='accuracy',\n",
    "            cv=5,\n",
    "            n_jobs=-1,\n",
    "            verbose=1\n",
    "        )\n",
    "\n",
    "        # Fit Grid Search\n",
    "        grid_search.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "        # Get best model\n",
    "        best_model = grid_search.best_estimator_\n",
    "        \n",
    "        # Print best parameters\n",
    "        print(\"\\nBest parameters found:\")\n",
    "        print(grid_search.best_params_)\n",
    "\n",
    "        # Predict with best model\n",
    "        y_pred = best_model.predict(X_test_smote)\n",
    "\n",
    "        # Evaluate\n",
    "        print(\"\\nModel Performance:\")\n",
    "        print(\"Accuracy:\", accuracy_score(y_test_smote, y_pred))\n",
    "        print(\"Precision:\", precision_score(y_test_smote, y_pred))\n",
    "        print(\"Recall:\", recall_score(y_test_smote, y_pred))\n",
    "        print(\"F1 Score:\", f1_score(y_test_smote, y_pred))\n",
    "\n",
    "        # Infer model signature\n",
    "        signature = infer_signature(X_train, y_pred)\n",
    "\n",
    "        # Log Dataset info\n",
    "        mlflow.log_input(dataset, context=\"training\")\n",
    "\n",
    "        # Log metrics\n",
    "        metrics = {\n",
    "            \"accuracy\": accuracy_score(y_test_smote, y_pred),\n",
    "            \"precision\": precision_score(y_test_smote, y_pred),\n",
    "            \"recall\": recall_score(y_test_smote, y_pred),\n",
    "            \"f1_score\": f1_score(y_test_smote, y_pred)\n",
    "        }\n",
    "\n",
    "        # Log all results to MLflow\n",
    "        mlflow.log_metrics(metrics)\n",
    "        mlflow.log_params(grid_search.best_params_)\n",
    "        \n",
    "        # Log cross-validation results\n",
    "        for i, score in enumerate(grid_search.cv_results_['mean_test_score']):\n",
    "            mlflow.log_metric(f\"cv_score_{i}\", score)\n",
    "\n",
    "        # Log best model with example\n",
    "        input_example = X_test_smote.iloc[:5] if hasattr(X_test_smote, \"iloc\") else X_test_smote[:5]\n",
    "        \n",
    "        mlflow.xgboost.log_model(\n",
    "            best_model,\n",
    "            name=\"XGBoost (SMOTE + Tuned)\",\n",
    "            signature=signature,\n",
    "            input_example=input_example\n",
    "        )\n",
    "\n",
    "# Function call\n",
    "SMOTE_Logging(X_train_diabetes, X_test_diabetes, y_test_diabetes, diabetes_mlflow)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5194423e",
   "metadata": {},
   "source": [
    "## PIMA-DIABETES DATSET WONT GO BEYOND 77% so stopping my work here, But previous experiments yielded Boost in Re-call, Precision, f1-score so its a success\n",
    "\n",
    "## Testing Parkinsons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6fe7bf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Bhand\\anaconda3\\envs\\prediction\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py:136: UserWarning: Could not find the number of physical cores for the following reason:\n",
      "[WinError 2] The system cannot find the file specified\n",
      "Returning the number of logical cores instead. You can silence this warning by setting LOKY_MAX_CPU_COUNT to the number of cores you want to use.\n",
      "  warnings.warn(\n",
      "  File \"c:\\Users\\Bhand\\anaconda3\\envs\\prediction\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py\", line 257, in _count_physical_cores\n",
      "    cpu_info = subprocess.run(\n",
      "        \"wmic CPU Get NumberOfCores /Format:csv\".split(),\n",
      "        capture_output=True,\n",
      "        text=True,\n",
      "    )\n",
      "  File \"c:\\Users\\Bhand\\anaconda3\\envs\\prediction\\Lib\\subprocess.py\", line 556, in run\n",
      "    with Popen(*popenargs, **kwargs) as process:\n",
      "         ~~~~~^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Bhand\\anaconda3\\envs\\prediction\\Lib\\subprocess.py\", line 1038, in __init__\n",
      "    self._execute_child(args, executable, preexec_fn, close_fds,\n",
      "    ~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "                        pass_fds, cwd, env,\n",
      "                        ^^^^^^^^^^^^^^^^^^^\n",
      "    ...<5 lines>...\n",
      "                        gid, gids, uid, umask,\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^\n",
      "                        start_new_session, process_group)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Bhand\\anaconda3\\envs\\prediction\\Lib\\subprocess.py\", line 1550, in _execute_child\n",
      "    hp, ht, pid, tid = _winapi.CreateProcess(executable, args,\n",
      "                       ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^\n",
      "                             # no special security\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<4 lines>...\n",
      "                             cwd,\n",
      "                             ^^^^\n",
      "                             startupinfo)\n",
      "                             ^^^^^^^^^^^^\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 256 candidates, totalling 1280 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Bhand\\anaconda3\\envs\\prediction\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [19:38:02] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best parameters found:\n",
      "{'colsample_bytree': 1.0, 'gamma': 0, 'learning_rate': 0.1, 'max_depth': 3, 'min_child_weight': 3, 'n_estimators': 200, 'scale_pos_weight': 2, 'subsample': 0.8}\n",
      "\n",
      "Model Performance:\n",
      "Accuracy: 0.9230769230769231\n",
      "Precision: 0.9333333333333333\n",
      "Recall: 0.9655172413793104\n",
      "F1 Score: 0.9491525423728814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Bhand\\anaconda3\\envs\\prediction\\Lib\\site-packages\\xgboost\\sklearn.py:1028: UserWarning: [19:38:17] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\c_api\\c_api.cc:1427: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\n",
      "  self.get_booster().save_model(fname)\n"
     ]
    }
   ],
   "source": [
    "def SMOTE_Logging_Parkinsons(X_train, X_test, y_test, dataset):\n",
    "    mlflow.set_experiment(\"Parkinsons_Experiment\")\n",
    "\n",
    "    with mlflow.start_run(run_name=\"XGBoost(SMOTE + Tuning + 5 Cross)\"):\n",
    "        # Load your parkinsons dataset\n",
    "        df = pd.read_csv(data_path_p)\n",
    "        df = df.drop(columns=['name'], axis=1)\n",
    "        X = df.drop(columns=[\"status\"])\n",
    "        y = df[\"status\"]\n",
    "\n",
    "        # Train-test split\n",
    "        X_train_smote, X_test_smote, y_train_smote, y_test_smote = train_test_split(\n",
    "            X, y, test_size=0.2, stratify=y, random_state=42\n",
    "        )\n",
    "\n",
    "        # Find and apply scalers \n",
    "        scaler = joblib.load(os.path.join('..','Trained_Models/Scalers/parkinsons_scaler.pkl'))\n",
    "        X_train_smote = scaler.transform(X_train_smote)\n",
    "        X_test_smote = scaler.transform(X_test_smote)\n",
    "\n",
    "        # Apply SMOTE\n",
    "        smote = SMOTE(random_state=42)\n",
    "        X_train_resampled, y_train_resampled = smote.fit_resample(X_train_smote, y_train_smote)\n",
    "\n",
    "        # Define parameter grid for XGBoost\n",
    "        param_grid = {\n",
    "            'n_estimators': [100, 200],\n",
    "            'max_depth': [3, 5],\n",
    "            'learning_rate': [0.01, 0.1],\n",
    "            'subsample': [0.8, 1.0],\n",
    "            'colsample_bytree': [0.8, 1.0],\n",
    "            'min_child_weight': [1, 3],\n",
    "            'gamma': [0, 0.1],\n",
    "            'scale_pos_weight': [1, 2]\n",
    "        }\n",
    "\n",
    "        # Initialize XGBoost with base parameters\n",
    "        xgb_model = XGBClassifier(\n",
    "            use_label_encoder=False,\n",
    "            eval_metric='logloss',\n",
    "            random_state=42\n",
    "        )\n",
    "\n",
    "        # Perform Grid Search\n",
    "        grid_search = GridSearchCV(\n",
    "            estimator=xgb_model,\n",
    "            param_grid=param_grid,\n",
    "            scoring='accuracy',\n",
    "            cv=5,\n",
    "            n_jobs=-1,\n",
    "            verbose=1\n",
    "        )\n",
    "\n",
    "        # Fit Grid Search\n",
    "        grid_search.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "        # Get best model\n",
    "        best_model = grid_search.best_estimator_\n",
    "        \n",
    "        # Print best parameters\n",
    "        print(\"\\nBest parameters found:\")\n",
    "        print(grid_search.best_params_)\n",
    "\n",
    "        # Predict with best model\n",
    "        y_pred = best_model.predict(X_test_smote)\n",
    "\n",
    "        # Evaluate\n",
    "        print(\"\\nModel Performance:\")\n",
    "        print(\"Accuracy:\", accuracy_score(y_test_smote, y_pred))\n",
    "        print(\"Precision:\", precision_score(y_test_smote, y_pred))\n",
    "        print(\"Recall:\", recall_score(y_test_smote, y_pred))\n",
    "        print(\"F1 Score:\", f1_score(y_test_smote, y_pred))\n",
    "\n",
    "        # Ensure X_test_smote is a DataFrame for signature and input_example\n",
    "        if not isinstance(X_test_smote, pd.DataFrame):\n",
    "            X_test_smote_df = pd.DataFrame(X_test_smote, columns=X.columns)\n",
    "        else:\n",
    "            X_test_smote_df = X_test_smote\n",
    "\n",
    "        # Infer model signature\n",
    "        signature = infer_signature(X_test_smote_df, y_pred)\n",
    "\n",
    "        # Log Dataset info\n",
    "        mlflow.log_input(dataset, context=\"training\")\n",
    "\n",
    "        # Log metrics\n",
    "        metrics = {\n",
    "            \"accuracy\": accuracy_score(y_test_smote, y_pred),\n",
    "            \"precision\": precision_score(y_test_smote, y_pred),\n",
    "            \"recall\": recall_score(y_test_smote, y_pred),\n",
    "            \"f1_score\": f1_score(y_test_smote, y_pred)\n",
    "        }\n",
    "\n",
    "        # Log all results to MLflow\n",
    "        mlflow.log_metrics(metrics)\n",
    "        mlflow.log_params(grid_search.best_params_)\n",
    "        \n",
    "        # Log cross-validation results\n",
    "        for i, score in enumerate(grid_search.cv_results_['mean_test_score']):\n",
    "            mlflow.log_metric(f\"cv_score_{i}\", score)\n",
    "\n",
    "        # Log best model with example\n",
    "        input_example = X_test_smote_df.iloc[:5]\n",
    "        \n",
    "        mlflow.xgboost.log_model(\n",
    "            best_model,\n",
    "            name=\"XGBoost (SMOTE + Tuned)\",\n",
    "            signature=signature,\n",
    "            input_example=input_example\n",
    "        )\n",
    "\n",
    "# Function call\n",
    "SMOTE_Logging_Parkinsons(X_train_parkinsons, X_test_parkinsons, y_test_parkinsons, parkinsons_mlflow)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6524c32",
   "metadata": {},
   "source": [
    "## Verified Parkinsons Model Moving to Heart_disease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b50ee262",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 256 candidates, totalling 1280 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Bhand\\anaconda3\\envs\\prediction\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [19:35:35] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\Bhand\\anaconda3\\envs\\prediction\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best parameters found:\n",
      "{'colsample_bytree': 1.0, 'gamma': 0.1, 'learning_rate': 0.1, 'max_depth': 3, 'min_child_weight': 3, 'n_estimators': 100, 'scale_pos_weight': 1, 'subsample': 0.8}\n",
      "\n",
      "Model Performance:\n",
      "Accuracy: 0.8688524590163934\n",
      "Precision: 0.8333333333333334\n",
      "Recall: 0.8928571428571429\n",
      "F1 Score: 0.8620689655172413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Bhand\\anaconda3\\envs\\prediction\\Lib\\site-packages\\xgboost\\sklearn.py:1028: UserWarning: [19:35:48] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\c_api\\c_api.cc:1427: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\n",
      "  self.get_booster().save_model(fname)\n"
     ]
    }
   ],
   "source": [
    "def SMOTE_Logging_Heart(dataset):\n",
    "    mlflow.set_experiment(\"Heart_Disease_Experiment\")\n",
    "\n",
    "    with mlflow.start_run(run_name=\"XGBoost(SMOTE + Scaler + Tuning + 5 Cross)\"):\n",
    "        # Load your parkinsons dataset\n",
    "        df = pd.read_csv(data_path_h)\n",
    "        X = df.drop(columns=[\"target\"])\n",
    "        y = df[\"target\"]\n",
    "\n",
    "        # Train-test split\n",
    "        X_train_smote, X_test_smote, y_train_smote, y_test_smote = train_test_split(\n",
    "            X, y, test_size=0.2, stratify=y, random_state=42\n",
    "        )\n",
    "        \n",
    "        # Find and apply scalers \n",
    "        scaler = joblib.load(os.path.join('..','Trained_Models/Scalers/heart_scaler.pkl'))\n",
    "        X_train_smote = scaler.transform(X_train_smote)\n",
    "        X_test_smote = scaler.transform(X_test_smote)\n",
    "\n",
    "        # Apply SMOTE\n",
    "        smote = SMOTE(random_state=42)\n",
    "        X_train_resampled, y_train_resampled = smote.fit_resample(X_train_smote, y_train_smote)\n",
    "\n",
    "        # Define parameter grid for XGBoost\n",
    "        param_grid = {\n",
    "            'n_estimators': [100, 200],\n",
    "            'max_depth': [3, 5],\n",
    "            'learning_rate': [0.01, 0.1],\n",
    "            'subsample': [0.8, 1.0],\n",
    "            'colsample_bytree': [0.8, 1.0],\n",
    "            'min_child_weight': [1, 3],\n",
    "            'gamma': [0, 0.1],\n",
    "            'scale_pos_weight': [1, 2]\n",
    "        }\n",
    "\n",
    "        # Initialize XGBoost with base parameters\n",
    "        xgb_model = XGBClassifier(\n",
    "            use_label_encoder=False,\n",
    "            eval_metric='logloss',\n",
    "            random_state=42\n",
    "        )\n",
    "\n",
    "        # Perform Grid Search\n",
    "        grid_search = GridSearchCV(\n",
    "            estimator=xgb_model,\n",
    "            param_grid=param_grid,\n",
    "            scoring='accuracy',\n",
    "            cv=5,\n",
    "            n_jobs=-1,\n",
    "            verbose=1\n",
    "        )\n",
    "\n",
    "        # Fit Grid Search\n",
    "        grid_search.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "        # Get best model\n",
    "        best_model = grid_search.best_estimator_\n",
    "        \n",
    "        # Print best parameters\n",
    "        print(\"\\nBest parameters found:\")\n",
    "        print(grid_search.best_params_)\n",
    "\n",
    "        # Predict with best model\n",
    "        y_pred = best_model.predict(X_test_smote)\n",
    "\n",
    "        # Evaluate\n",
    "        print(\"\\nModel Performance:\")\n",
    "        print(\"Accuracy:\", accuracy_score(y_test_smote, y_pred))\n",
    "        print(\"Precision:\", precision_score(y_test_smote, y_pred))\n",
    "        print(\"Recall:\", recall_score(y_test_smote, y_pred))\n",
    "        print(\"F1 Score:\", f1_score(y_test_smote, y_pred))\n",
    "\n",
    "        # Ensure X_test_smote is a DataFrame for signature and input_example\n",
    "        if not isinstance(X_test_smote, pd.DataFrame):\n",
    "            X_test_smote_df = pd.DataFrame(X_test_smote, columns=X.columns)\n",
    "        else:\n",
    "            X_test_smote_df = X_test_smote\n",
    "\n",
    "        # Infer model signature\n",
    "        signature = infer_signature(X_test_smote_df, y_pred)\n",
    "\n",
    "        # Log Dataset info\n",
    "        mlflow.log_input(dataset, context=\"training\")\n",
    "\n",
    "        # Log metrics\n",
    "        metrics = {\n",
    "            \"accuracy\": accuracy_score(y_test_smote, y_pred),\n",
    "            \"precision\": precision_score(y_test_smote, y_pred),\n",
    "            \"recall\": recall_score(y_test_smote, y_pred),\n",
    "            \"f1_score\": f1_score(y_test_smote, y_pred)\n",
    "        }\n",
    "\n",
    "        # Log all results to MLflow\n",
    "        mlflow.log_metrics(metrics)\n",
    "        mlflow.log_params(grid_search.best_params_)\n",
    "        \n",
    "        # Log cross-validation results\n",
    "        for i, score in enumerate(grid_search.cv_results_['mean_test_score']):\n",
    "            mlflow.log_metric(f\"cv_score_{i}\", score)\n",
    "\n",
    "        # Log best model with example\n",
    "        input_example = X_test_smote_df.iloc[:5]\n",
    "        \n",
    "        mlflow.xgboost.log_model(\n",
    "            best_model,\n",
    "            name=\"XGBoost (SMOTE + Tuned)\",\n",
    "            signature=signature,\n",
    "            input_example=input_example\n",
    "        )\n",
    "\n",
    "# Function call\n",
    "SMOTE_Logging_Heart(parkinsons_mlflow)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prediction",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
